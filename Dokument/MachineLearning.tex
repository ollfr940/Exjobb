\chapter{Machine learning methods}
\label{sec:Machine learning methods}

\section{AdaBoost}
\label{sec:AdaBoost}
The machine learning method that will be tried out first is Boosting which is described in [2]. The basic idea is to train a number of weak classifiers which during the testing will be combined to a strong classifier. To each data in the training dataset there are corresponding weights which are equal for all data at the beginning. The weak classifiers are trained sequentially and after each step the weights are adjusted depending if they were correctly or incorrectly classified.

There exist several variants of Boosting algorithms. The one that will be tried out first is discrete AdaBoost. The weak classifiers in discrete AdaBoost are split functions which simply classifies the data as true or false. The split functions consist of a number of different parameters. The most basic function, which will be tried out first, only has one parameter, a threshold. The function search for a threshold in one dimension at a time and choose the one whish best separates the data. 
% Local Variables:
% TeX-master: "main.tex"
% End:
